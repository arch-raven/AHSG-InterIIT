{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPtlnuuM-4nW",
    "outputId": "7759c719-9974-410f-9f02-6cf11caca530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/e2/84d6acfcee2d83164149778a33b6bdd1a74e1bcb59b2b2cd1b861359b339/sentence-transformers-0.4.1.2.tar.gz (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
      "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 12.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 43.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 36.7MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 39.8MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (0.6)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
      "Building wheels for collected packages: sentence-transformers, sacremoses\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-cp37-none-any.whl size=103068 sha256=7e2bc114f2e7cced22cbba5f4770bc18202b0fb82bc1eb32a36d00d9b44232f8\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/33/d1/5703dd56199c09d4a1b41e0c07fb4e7765a84d787cbdc48ac3\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=f99223805fbde7a259f0fd2fc4dd63d3b31a92ec1e771e870cd82cc2fe83b0ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sentence-transformers sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
      "Successfully installed sacremoses-0.0.43 sentence-transformers-0.4.1.2 sentencepiece-0.1.95 tokenizers-0.10.1 transformers-4.3.3\n",
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\r\n",
    "!pip install -U rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pW5FB4yK-_0q",
    "outputId": "7396f983-a051-4d90-d937-40503b8d886b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import scipy\r\n",
    "import pandas as pd\r\n",
    "from sentence_transformers import SentenceTransformer\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from rouge import Rouge\r\n",
    "from statistics import mean\r\n",
    "import nltk\r\n",
    "nltk.download('punkt')\r\n",
    "\r\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROvj6m4C_JXS",
    "outputId": "d10cb059-b21d-4e31-d70c-67e5a4b8bf9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405M/405M [00:07<00:00, 53.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.8060\n"
     ]
    }
   ],
   "source": [
    "# Get average document similarity using BERT\r\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\r\n",
    "\r\n",
    "# Get a vector for each headlines\r\n",
    "actual_headline = 'West Bengal: BJP Holds Mega Rally In Nandigram Ahead Of JP Naddas Visit'\r\n",
    "predicted_headline = 'Battleground Bengal: Dilip Ghosh Holds Rally In Howrah, Says, West Bengal Has Faith In BJP'\r\n",
    "actual_headline_embeddings = model.encode(actual_headline)\r\n",
    "predicted_headline_embeddings = model.encode(predicted_headline)\r\n",
    "\r\n",
    "distance = scipy.spatial.distance.cdist([actual_headline_embeddings], [predicted_headline_embeddings], \"cosine\")[0]\r\n",
    "print(\"Similarity Score: %.4f\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CRnV-i3_ml7",
    "outputId": "8f7f99e0-7c02-4c89-e5b1-26006047c906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': 0.2962962913031551, 'p': 0.3076923076923077, 'r': 0.2857142857142857}"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rouge Scores\r\n",
    "rouge = Rouge()\r\n",
    "\r\n",
    "# Headlines Actual and Predicted\r\n",
    "actual_headline = 'West Bengal: BJP Holds Mega Rally In Nandigram Ahead Of JP Naddas Visit'\r\n",
    "predicted_headline = 'Battleground Bengal: Dilip Ghosh Holds Rally In Howrah, Says, West Bengal Has Faith In BJP'\r\n",
    "\r\n",
    "rouge_score = rouge.get_scores(actual_headline, predicted_headline)\r\n",
    "rouge_scores = rouge_score[0]['rouge-l']\r\n",
    "\r\n",
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEyw7p3DAOzM",
    "outputId": "536172e8-b2a6-496e-d43a-d99bf43d2b55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4111336169005197"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLEU Scores\r\n",
    "actual_headline = 'West Bengal: BJP Holds Mega Rally In Nandigram Ahead Of JP Naddas Visit'\r\n",
    "predicted_headline = 'Battleground Bengal: Dilip Ghosh Holds Rally In Howrah, Says, West Bengal Has Faith In BJP'\r\n",
    "\r\n",
    "hypothesis = predicted_headline.split()\r\n",
    "reference = actual_headline.split()\r\n",
    "references = [reference] # list of references for 1 sentence.\r\n",
    "list_of_references = [references] # list of references for all sentences in corpus.\r\n",
    "list_of_hypotheses = [hypothesis] # list of hypotheses that corresponds to list of references.\r\n",
    "bleu_score = corpus_bleu(list_of_references, list_of_hypotheses)\r\n",
    "\r\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjdLsaZUAopo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Headline_similarity_scores.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
